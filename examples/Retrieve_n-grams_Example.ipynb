{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve n-grams: Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows the different options for performing the extraction of n-grams from a tagged text using the corpora toolbox. The tagged text must be provided as a list of Tag objects (from the corpora_toolbox.nlp.**NLP_classes**).\n",
    "\n",
    "The retrieve_n_grams fucntion from the corpora_toolbox.nlp.**NLP_classics** has the following particularities:\n",
    "\n",
    "1. It extracts n-grams taking into account the period (indicated by the tagger with the tag \"Fp\", following the [FreeLing](http://nlp.lsi.upc.edu/freeling/) tagging style) as a sentence chunker. This means that two words that are separated by a perdiod identified as a sentence breaker by a tagger, won't be a part of the same n-gram. For example, in \"I am happy. The sun is shinning.\", there won't be \"happy_the as a bigram, since the sentence has a basic chunker based on the preriod sign.\n",
    "2. The retriever allows the extraction of n-grams of POS, original tokens or lemmas.\n",
    "3. It also permits the attachment of the tag to the n-gram. This allows the differentiation between n-grams that include **homonyms**. For example, \"*bear/N*\" (the animal) and \"*bear/V*\" (to withstand)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the relative path for importing the corpora_toolbox "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "\n",
    "if platform.platform().lower().startswith(\"windows\"):\n",
    "    relative_path=\"..\\\\\\\\\"\n",
    "else:\n",
    "    relative_path=\"../\"\n",
    "\n",
    "sys.path.append(relative_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpora_toolbox.nlp.NLP_primitives import Tag\n",
    "from corpora_toolbox.nlp.NLP_classics import retrieve_n_grams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating a list of Tag objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The n-grams will be retreived from the phrase \"Ver√≥nica has a dog, and a cat, and a mouse, and an alligator. Laura has a rabbit.\". The following section, creates a list of Tag objects filled with the part of speech tagging and lemmatization of the phrase.\n",
    "\n",
    "POS tags: \n",
    "\n",
    "    N = noun\n",
    "    V = verb\n",
    "    D = determinant\n",
    "    F = Punctuation Sign\n",
    "        Fc = comma\n",
    "        Fp = period\n",
    "    C = conjunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_tags = []\n",
    "\n",
    "list_of_tags.append( Tag(\"Veronica\", \"veronica\", \"N\") )\n",
    "list_of_tags.append( Tag(\"has\", \"have\", \"V\") )\n",
    "list_of_tags.append( Tag(\"a\", \"a\", \"D\") )\n",
    "list_of_tags.append( Tag(\"dog\", \"dog\", \"N\") )\n",
    "list_of_tags.append( Tag(\",\", \",\", \"Fc\") )\n",
    "list_of_tags.append( Tag(\"and\", \"and\", \"C\") )\n",
    "list_of_tags.append( Tag(\"a\", \"a\", \"D\") )\n",
    "list_of_tags.append( Tag(\"cat\", \"cat\", \"N\") )\n",
    "list_of_tags.append( Tag(\",\", \",\", \"Fc\") )\n",
    "list_of_tags.append( Tag(\"and\", \"and\", \"C\") )\n",
    "list_of_tags.append( Tag(\"a\", \"a\", \"D\") )\n",
    "list_of_tags.append( Tag(\"mouse\", \"mouse\", \"N\") )\n",
    "list_of_tags.append( Tag(\",\", \",\", \"Fc\") )\n",
    "list_of_tags.append( Tag(\"and\", \"and\", \"C\") )\n",
    "list_of_tags.append( Tag(\"an\", \"a\", \"D\") )\n",
    "list_of_tags.append( Tag(\"animal\", \"alligator\", \"N\") )\n",
    "list_of_tags.append( Tag(\".\", \".\", \"Fp\") )\n",
    "list_of_tags.append( Tag(\"Laura\", \"laura\", \"N\") )\n",
    "list_of_tags.append( Tag(\"has\", \"have\", \"V\") )\n",
    "list_of_tags.append( Tag(\"a\", \"a\", \"D\") )\n",
    "list_of_tags.append( Tag(\"rabbit\", \"rabbit\", \"N\") )\n",
    "list_of_tags.append( Tag(\".\", \".\", \"Fp\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the default options to extract n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the *retrieve_n_grams* fucntion retrieves the n-grams of lemmas, without considering punctuation marks. Following the [FreeLing](http://nlp.lsi.upc.edu/freeling/) tagging style, punctuation marks tags always start with \"F\". \n",
    "\n",
    "**NOTE**: Regardless of the value of the *remove_punctuation* parameter, *retrieve_n_grams* will always consider the \"Fp\" (period) tag as the chunker mark to separate sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-grams:  ['veronica', 'have', 'a', 'dog', 'and', 'a', 'cat', 'and', 'a', 'mouse', 'and', 'a', 'alligator', 'laura', 'have', 'a', 'rabbit'] \n",
      "\n",
      "2-grams:  ['veronica_have', 'have_a', 'a_dog', 'dog_and', 'and_a', 'a_cat', 'cat_and', 'and_a', 'a_mouse', 'mouse_and', 'and_a', 'a_alligator', 'laura_have', 'have_a', 'a_rabbit'] \n",
      "\n",
      "3-grams:  ['veronica_have_a', 'have_a_dog', 'a_dog_and', 'dog_and_a', 'and_a_cat', 'a_cat_and', 'cat_and_a', 'and_a_mouse', 'a_mouse_and', 'mouse_and_a', 'and_a_alligator', 'laura_have_a', 'have_a_rabbit'] \n",
      "\n",
      "4-grams:  ['veronica_have_a_dog', 'have_a_dog_and', 'a_dog_and_a', 'dog_and_a_cat', 'and_a_cat_and', 'a_cat_and_a', 'cat_and_a_mouse', 'and_a_mouse_and', 'a_mouse_and_a', 'mouse_and_a_alligator', 'laura_have_a_rabbit'] \n",
      "\n",
      "5-grams:  ['veronica_have_a_dog_and', 'have_a_dog_and_a', 'a_dog_and_a_cat', 'dog_and_a_cat_and', 'and_a_cat_and_a', 'a_cat_and_a_mouse', 'cat_and_a_mouse_and', 'and_a_mouse_and_a', 'a_mouse_and_a_alligator'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "unigrams = retrieve_n_grams(1, list_of_tags)\n",
    "bigrams = retrieve_n_grams(2, list_of_tags)\n",
    "trigrams = retrieve_n_grams(3, list_of_tags)\n",
    "tetragrams = retrieve_n_grams(4, list_of_tags)\n",
    "pentagrams = retrieve_n_grams(5, list_of_tags)\n",
    "\n",
    "print(\"1-grams: \", unigrams, \"\\n\")\n",
    "print(\"2-grams: \", bigrams, \"\\n\")\n",
    "print(\"3-grams: \", trigrams, \"\\n\")\n",
    "print(\"4-grams: \", tetragrams, \"\\n\")\n",
    "print(\"5-grams: \", pentagrams, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**- Bonus tip: -** You can easily get a dictionary with the frequency of n-grams by using the Counter subclass from collections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'a': 5, 'and': 3, 'have': 2, 'veronica': 1, 'dog': 1, 'cat': 1, 'mouse': 1, 'alligator': 1, 'laura': 1, 'rabbit': 1}) \n",
      "\n",
      "Counter({'and_a': 3, 'have_a': 2, 'veronica_have': 1, 'a_dog': 1, 'dog_and': 1, 'a_cat': 1, 'cat_and': 1, 'a_mouse': 1, 'mouse_and': 1, 'a_alligator': 1, 'laura_have': 1, 'a_rabbit': 1}) \n",
      "\n",
      "Counter({'veronica_have_a': 1, 'have_a_dog': 1, 'a_dog_and': 1, 'dog_and_a': 1, 'and_a_cat': 1, 'a_cat_and': 1, 'cat_and_a': 1, 'and_a_mouse': 1, 'a_mouse_and': 1, 'mouse_and_a': 1, 'and_a_alligator': 1, 'laura_have_a': 1, 'have_a_rabbit': 1}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "\n",
    "print(Counter(unigrams),\"\\n\")\n",
    "print(Counter(bigrams),\"\\n\")\n",
    "print(Counter(trigrams),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving n-grams of the original words (without lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-grams:  ['Veronica', 'has', 'a', 'dog', 'and', 'a', 'cat', 'and', 'a', 'mouse', 'and', 'an', 'animal', 'Laura', 'has', 'a', 'rabbit'] \n",
      "\n",
      "2-grams:  ['Veronica_has', 'has_a', 'a_dog', 'dog_and', 'and_a', 'a_cat', 'cat_and', 'and_a', 'a_mouse', 'mouse_and', 'and_an', 'an_animal', 'Laura_has', 'has_a', 'a_rabbit'] \n",
      "\n",
      "3-grams:  ['Veronica_has_a', 'has_a_dog', 'a_dog_and', 'dog_and_a', 'and_a_cat', 'a_cat_and', 'cat_and_a', 'and_a_mouse', 'a_mouse_and', 'mouse_and_an', 'and_an_animal', 'Laura_has_a', 'has_a_rabbit'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "unigrams = retrieve_n_grams(1,list_of_tags, lemmas=False)\n",
    "bigrams = retrieve_n_grams(2, list_of_tags, lemmas=False)\n",
    "trigrams = retrieve_n_grams(3, list_of_tags, lemmas=False)\n",
    "\n",
    "print(\"1-grams: \", unigrams, \"\\n\")\n",
    "print(\"2-grams: \", bigrams, \"\\n\")\n",
    "print(\"3-grams: \", trigrams, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Including punctuation marks in the n-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-grams:  ['veronica', 'have', 'a', 'dog', ',', 'and', 'a', 'cat', ',', 'and', 'a', 'mouse', ',', 'and', 'a', 'alligator', 'laura', 'have', 'a', 'rabbit'] \n",
      "\n",
      "2-grams:  ['veronica_have', 'have_a', 'a_dog', 'dog_,', ',_and', 'and_a', 'a_cat', 'cat_,', ',_and', 'and_a', 'a_mouse', 'mouse_,', ',_and', 'and_a', 'a_alligator', 'laura_have', 'have_a', 'a_rabbit'] \n",
      "\n",
      "3-grams:  ['veronica_have_a', 'have_a_dog', 'a_dog_,', 'dog_,_and', ',_and_a', 'and_a_cat', 'a_cat_,', 'cat_,_and', ',_and_a', 'and_a_mouse', 'a_mouse_,', 'mouse_,_and', ',_and_a', 'and_a_alligator', 'laura_have_a', 'have_a_rabbit'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "unigrams = retrieve_n_grams(1,list_of_tags, remove_punctuation=False)\n",
    "bigrams = retrieve_n_grams(2, list_of_tags, remove_punctuation=False)\n",
    "trigrams = retrieve_n_grams(3, list_of_tags, remove_punctuation=False)\n",
    "\n",
    "print(\"1-grams: \", unigrams, \"\\n\")\n",
    "print(\"2-grams: \", bigrams, \"\\n\")\n",
    "print(\"3-grams: \", trigrams, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attaching the tags to the n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-grams:  ['veronica/N', 'have/V', 'a/D', 'dog/N', 'and/C', 'a/D', 'cat/N', 'and/C', 'a/D', 'mouse/N', 'and/C', 'a/D', 'alligator/N', 'laura/N', 'have/V', 'a/D', 'rabbit/N'] \n",
      "\n",
      "2-grams:  ['veronica_have/N_V', 'have_a/V_D', 'a_dog/D_N', 'dog_and/N_C', 'and_a/C_D', 'a_cat/D_N', 'cat_and/N_C', 'and_a/C_D', 'a_mouse/D_N', 'mouse_and/N_C', 'and_a/C_D', 'a_alligator/D_N', 'laura_have/N_V', 'have_a/V_D', 'a_rabbit/D_N'] \n",
      "\n",
      "3-grams:  ['veronica_have_a/N_V_D', 'have_a_dog/V_D_N', 'a_dog_and/D_N_C', 'dog_and_a/N_C_D', 'and_a_cat/C_D_N', 'a_cat_and/D_N_C', 'cat_and_a/N_C_D', 'and_a_mouse/C_D_N', 'a_mouse_and/D_N_C', 'mouse_and_a/N_C_D', 'and_a_alligator/C_D_N', 'laura_have_a/N_V_D', 'have_a_rabbit/V_D_N'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "unigrams = retrieve_n_grams(1,list_of_tags, only_tokens=False)\n",
    "bigrams = retrieve_n_grams(2, list_of_tags, only_tokens=False)\n",
    "trigrams = retrieve_n_grams(3, list_of_tags, only_tokens=False)\n",
    "\n",
    "print(\"1-grams: \", unigrams, \"\\n\")\n",
    "print(\"2-grams: \", bigrams, \"\\n\")\n",
    "print(\"3-grams: \", trigrams, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retreiving n-grams of the POS tags only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For linguistic analysis, it is common to analyze patterns of n-grams considering only the POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-grams:  ['N', 'V', 'D', 'N', 'C', 'D', 'N', 'C', 'D', 'N', 'C', 'D', 'N', 'N', 'V', 'D', 'N'] \n",
      "\n",
      "2-grams:  ['N_V', 'V_D', 'D_N', 'N_C', 'C_D', 'D_N', 'N_C', 'C_D', 'D_N', 'N_C', 'C_D', 'D_N', 'N_V', 'V_D', 'D_N'] \n",
      "\n",
      "3-grams:  ['N_V_D', 'V_D_N', 'D_N_C', 'N_C_D', 'C_D_N', 'D_N_C', 'N_C_D', 'C_D_N', 'D_N_C', 'N_C_D', 'C_D_N', 'N_V_D', 'V_D_N'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "unigrams = retrieve_n_grams(1,list_of_tags, only_tags=True)\n",
    "bigrams = retrieve_n_grams(2, list_of_tags, only_tags=True)\n",
    "trigrams = retrieve_n_grams(3, list_of_tags, only_tags=True)\n",
    "\n",
    "print(\"1-grams: \", unigrams, \"\\n\")\n",
    "print(\"2-grams: \", bigrams, \"\\n\")\n",
    "print(\"3-grams: \", trigrams, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
